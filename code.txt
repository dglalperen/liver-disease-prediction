import numpy as np
import pandas as pd
from sklearn.feature_selection import VarianceThreshold
import datetime as dt
import sklearn
from scipy import stats
from sklearn import preprocessing
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from sklearn.pipeline import make_pipeline
from collections import Counter
from sklearn.feature_selection import RFECV
import warnings
warnings.filterwarnings("ignore")

from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score


encoder = preprocessing.LabelEncoder()

#data = pd.read_excel("indian liver.xlsx")
data = pd.read_csv("../data/raw_data/indian_liver_patient.csv")

# duplicated rows

data.duplicated().sum()

duplicate = data[data.duplicated()]
  
print("Duplicate Rows :")

# Print the resultant Dataframe
duplicate

data.duplicated().sum() --> 13

# Remove duplicated rows

data.drop_duplicates(keep=False, inplace=True)
data.duplicated().sum()

data.shape
data.Dataset.value_counts()

Dataset
1    396
2    161
Name: count, dtype: int64
unique_values = data['Dataset'].unique()
print("Unique values in 'Dataset':", unique_values)
Unique values in 'Dataset': [1 2]


import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 6))

# Plot the number of 1's and 2's
g = sns.countplot(x='Dataset', data=data)

# Set x-axis labels for the two categories
g.set_xticklabels(['Normal', 'Liver'])

plt.show()
#data preparation
y = data["Dataset"]
X = data.drop(["Dataset"],axis=1)


X.isna().sum()
X.isna().sum().sum() --> 0

from imblearn.pipeline import make_pipeline as make_pipeline_imb # To do our transformation in a unique time
from imblearn.combine import SMOTEENN
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTEN

# build model with SMOTE imblearn
# smote_pipeline = make_pipeline_imb(SMOTE(random_state=0))

smote_pipeline = RandomOverSampler(random_state=0)

# smote_pipeline = ADASYN(random_state=0, n_neighbors=4)
smote_model = smote_pipeline.fit(X, y)

#Showing the diference before and after the transformation used
print("normal data distribution: {}".format(Counter(y)))

X_smote, y_smote = smote_model.fit_resample(X, y)

print("SMOTE data distribution: {}".format(Counter(y_smote)))
normal data distribution: Counter({1: 396, 2: 161})
SMOTE data distribution: Counter({1: 396, 2: 396})
import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the correlation of each feature in X_smote with y_smote
correlations_with_target = X_smote.apply(lambda x: x.corr(y_smote))

# Select features based on a correlation threshold
threshold = 0.1
features_above_threshold = correlations_with_target[abs(correlations_with_target) > threshold].index.tolist()

# Create the final dataset with the selected features
X_new = X_smote[features_above_threshold]
print("Feature Count:", X_new.shape[1])
print("Selected features based on correlation threshold:", features_above_threshold)

# Heatmap of correlations
plt.figure(figsize=(10, 8))
sns.heatmap(X_smote[features_above_threshold].corr(), annot=True, fmt=".2f")
plt.title("Correlation Heatmap of Selected Features")
plt.show()
Feature Count: 8
Selected features based on correlation threshold: ['Age', 'Total_Bilirubin', 'Direct_Bilirubin', 'Alkaline_Phosphotase', 'Alamine_Aminotransferase', 'Aspartate_Aminotransferase', 'Albumin', 'Albumin_and_Globulin_Ratio']

from sklearn.ensemble import RandomForestClassifier

from yellowbrick.datasets import load_occupancy
from yellowbrick.model_selection import FeatureImportances

model = RandomForestClassifier(n_estimators=10)
viz = FeatureImportances(model)
viz.fit(X_new, y_smote)
viz.show()

from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import numpy as np

# Define base models for the stacking classifier
base_models = [
    ('rf', RandomForestClassifier(n_estimators=100, random_state=22)),
    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=22)),
    # ('svc', SVC(probability=True, random_state=22)),
    # ('knn', KNeighborsClassifier()),
    # ('dt', DecisionTreeClassifier(random_state=22))
    ('ET', ExtraTreesClassifier(n_estimators=120, random_state=22)),
    
]

# Define the meta-model
meta_model = LogisticRegression()

# Create the stacking classifier with cross-validation
stacking_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
)

# Train and evaluate the stacking model using the resampled data
accuracy_scores = []
for train_index, test_index in StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(X_new, y_smote):
    X_train, X_test = X_new.iloc[train_index], X_new.iloc[test_index]
    y_train, y_test = y_smote.iloc[train_index], y_smote.iloc[test_index]

    stacking_model.fit(X_train, y_train)
    y_pred = stacking_model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    accuracy_scores.append(accuracy)

# Calculate and print the average accuracy across folds
average_accuracy = np.mean(accuracy_scores)
print(f"Average Accuracy: {average_accuracy:.4f}")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import numpy as np

accuracy_scores = []
precision_scores = []
recall_scores = []
f1_scores = []
roc_auc_scores = []

for train_index, test_index in StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(X_new, y_smote):
    X_train, X_test = X_new.iloc[train_index], X_new.iloc[test_index]
    y_train, y_test = y_smote.iloc[train_index], y_smote.iloc[test_index]

    stacking_model.fit(X_train, y_train)
    y_pred = stacking_model.predict(X_test)

    accuracy_scores.append(accuracy_score(y_test, y_pred))
    precision_scores.append(precision_score(y_test, y_pred))
    recall_scores.append(recall_score(y_test, y_pred))
    f1_scores.append(f1_score(y_test, y_pred))
    roc_auc_scores.append(roc_auc_score(y_test, y_pred))

# Calculate and print the average scores across folds
print(f"Average Accuracy: {np.mean(accuracy_scores):.4f}")
print(f"Average Precision: {np.mean(precision_scores):.4f}")
print(f"Average Recall: {np.mean(recall_scores):.4f}")
print(f"Average F1 Score: {np.mean(f1_scores):.4f}")
print(f"Average ROC-AUC Score: {np.mean(roc_auc_scores):.4f}")

Average Accuracy: 0.9104
Average Precision: 0.8932
Average Recall: 0.9346
Average F1 Score: 0.9129
Average ROC-AUC Score: 0.9104